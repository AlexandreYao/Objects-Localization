{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from customDataset import CustomDataset\n","from torchinfo import summary\n","from torch.utils.data import DataLoader\n","import matplotlib.patches as patches\n","from tqdm import tqdm\n","import random\n","import torch.optim as optim\n","import torch\n","import torch.nn as nn\n","\n","from utils import *\n","from torchvision.models import vgg16, VGG16_Weights\n","\n","manualSeed = 999 \n","print(\"Random Seed: \", manualSeed)\n","random.seed(manualSeed)\n","torch.manual_seed(manualSeed)\n","torch.use_deterministic_algorithms(True)  \n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"runnning on {device}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batch_size = 32\n","image_size = 224\n","train_dataset = CustomDataset(\n","    image_folders=[\n","        r\"..\\data\\black-and-white-rectangle\\train\",\n","    ],\n","    image_extension=\".png\",\n","    image_size=image_size,\n",")\n","test_dataset = CustomDataset(\n","    image_folders=[\n","        r\"..\\data\\black-and-white-rectangle\\val\",\n","    ],\n","    image_extension=\".png\",\n","    image_size=image_size,\n",")\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n","len(train_dataset), len(test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def show_images_with_bboxes(dataset, num_images=12, num_cols=4):\n","    \"\"\"\n","    Affiche des exemples d'images avec leurs boîtes englobantes associées.\n","    Args:\n","        dataset (Dataset): Instance de CustomDataset.\n","        num_images (int, optional): Nombre d'images à afficher. Par défaut 12.\n","        num_cols (int, optional): Nombre de colonnes dans l'affichage. Par défaut 4.\n","    \"\"\"\n","    num_rows = (num_images + num_cols - 1) // num_cols  # Calcul du nombre de lignes\n","    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 5, num_rows * 5))\n","    axes = axes.flatten()  # Aplatit la grille d'axes pour un accès plus facile\n","\n","    for i in range(num_images):\n","        sample = dataset[i]\n","        image = sample['input_img'].numpy().transpose((1, 2, 0))  # Convertir en HWC pour plt\n","        label = sample['label'].numpy().reshape(-1, 5)\n","\n","        axes[i].imshow(image)\n","        axes[i].axis(\"off\")\n","\n","        # Tracer les boîtes englobantes\n","        for bbox in label:\n","            class_id, x_center, y_center, width, height = bbox\n","            x_center *= image.shape[1]\n","            y_center *= image.shape[0]\n","            width *= image.shape[1]\n","            height *= image.shape[0]\n","\n","            x1 = x_center - width / 2\n","            y1 = y_center - height / 2\n","\n","            rect = patches.Rectangle(\n","                (x1, y1), width, height, linewidth=2, edgecolor='g', facecolor='none'\n","            )\n","            axes[i].add_patch(rect)\n","\n","    # Supprime les axes inutilisés\n","    for j in range(i + 1, len(axes)):\n","        axes[j].axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Exemple d'utilisation\n","show_images_with_bboxes(train_dataset, num_images=12, num_cols=4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input_size = (batch_size, 3, 224, 224)\n","model = vgg16(weights=VGG16_Weights.DEFAULT)\n","# Freeze training for all layers\n","for param in model.parameters():\n","    param.require_grad = False\n","# print(model)\n","# summary(\n","#     model,\n","#     input_size=input_size,\n","#     col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n","#     col_width=20,\n","#     row_settings=[\"var_names\"],\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_inputs = model.classifier[6].in_features\n","model.classifier[6] =  nn.Sequential(\n","    nn.Linear(n_inputs, 4),\n","    nn.Sigmoid()\n",")\n","model = model.to(device)\n","summary(\n","    model,\n","    input_size=input_size,\n","    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n","    col_width=20,\n","    row_settings=[\"var_names\"],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def calculate_iou(bbox_pred, bbox_target):\n","    \"\"\"\n","    Calculate Intersection over Union (IoU) between two bounding boxes.\n","    Args:\n","        bbox_pred (torch.Tensor): Predicted bounding box of shape (4,).\n","        bbox_target (torch.Tensor): Target bounding box of shape (4,).\n","    Returns:\n","        float: Intersection over Union (IoU) score.\n","    \"\"\"\n","    # Extract coordinates\n","    x1_pred, y1_pred, w_pred, h_pred = bbox_pred\n","    x1_target, y1_target, w_target, h_target = bbox_target\n","    \n","    # Calculate coordinates of intersection rectangle\n","    x1_inter = max(x1_pred, x1_target)\n","    y1_inter = max(y1_pred, y1_target)\n","    x2_inter = min(x1_pred + w_pred, x1_target + w_target)\n","    y2_inter = min(y1_pred + h_pred, y1_target + h_target)\n","    \n","    # Calculate area of intersection rectangle\n","    inter_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)\n","    \n","    # Calculate area of union of both rectangles\n","    pred_area = w_pred * h_pred\n","    target_area = w_target * h_target\n","    union_area = pred_area + target_area - inter_area\n","    \n","    # Calculate IoU\n","    iou = inter_area / union_area if union_area > 0 else 0.0\n","    \n","    return iou\n","def train_bbox_regression_model(\n","    model,\n","    optimizer,\n","    criterion,\n","    train_dataloader,\n","    val_dataloader,\n","    num_epochs,\n","    device,\n","    scheduler=None,\n","    plot_figs=True,\n","    nb_batches_to_display=10,\n","    early_stopper=None,\n","    save_filepath=None\n","):\n","    \"\"\"\n","    Train a bounding box regression model.\n","    Args:\n","        model (torch.nn.Module): The model to train.\n","        optimizer (torch.optim.Optimizer): The optimizer used for training.\n","        criterion (torch.nn.Module): The loss function.\n","        train_dataloader (torch.utils.data.DataLoader): DataLoader for the training set.\n","        val_dataloader (torch.utils.data.DataLoader): DataLoader for the validation set.\n","        num_epochs (int): Number of epochs for training.\n","        device (torch.device): Device to use for training (e.g., 'cpu', 'cuda').\n","        scheduler (optional): Learning rate scheduler.\n","        plot_figs (bool): Whether to plot training and validation curves.\n","        nb_batches_to_display (int): Number of batches to display during training.\n","        early_stopper (optional): Early stopping mechanism.\n","        save_filepath(optional): Path to save the model\n","    Returns:\n","        tuple: Tuple containing the trained model and training history.\n","    \"\"\"\n","    print(f\"Train: model={type(model).__name__}, opt={type(optimizer).__name__}(lr={optimizer.param_groups[0]['lr']}), num_epochs={num_epochs}, device={device}\\n\")\n","    history = {\"loss\": [], \"val_loss\": [], \"iou\": [], \"val_iou\": []}\n","    start_time_sec = time.time()\n","    for epoch in range(1, num_epochs + 1):\n","        print(f\"Epoch {epoch}/{num_epochs}\")\n","        print(\"=\" * 60)\n","        # TRAINING\n","        model.train()\n","        train_loss = 0.0\n","        total_iou = 0.0\n","        num_train_examples = 0\n","        for batch_index, data in enumerate(train_dataloader):\n","            optimizer.zero_grad()\n","            inputs, targets = data[\"input_img\"], data[\"label\"].squeeze(1)[:, :4]\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","            loss.backward()\n","            optimizer.step()\n","            if scheduler is not None:\n","                scheduler.step()\n","            train_loss += loss.item() * inputs.size(0)\n","            num_train_examples += inputs.size(0)\n","            # Calculate IoU\n","            with torch.no_grad():\n","                for pred, target in zip(outputs, targets):\n","                    iou = calculate_iou(pred, target)\n","                    total_iou += iou.item()\n","            if (nb_batches_to_display > 0 and (batch_index + 1) % nb_batches_to_display == 0):\n","                print(f\"\\tBatch {batch_index+1}/{len(train_dataloader)}, loss: {train_loss / num_train_examples:.4f}\")\n","        \n","        train_loss = train_loss / len(train_dataloader.dataset)\n","        train_iou = total_iou / num_train_examples if num_train_examples > 0 else 0.0\n","        \n","        # VALIDATION\n","        model.eval()\n","        val_loss = 0.0\n","        total_val_iou = 0.0\n","        num_val_batches = 0\n","        with torch.no_grad():\n","            for data in val_dataloader:\n","                inputs, targets = data[\"input_img\"], data[\"label\"].squeeze(1)[:, :4]\n","                inputs, targets = inputs.to(device), targets.to(device)\n","                outputs = model(inputs)\n","                loss = criterion(outputs, targets)\n","                val_loss += loss.item() * inputs.size(0)\n","                \n","                # Calculate IoU\n","                for pred, target in zip(outputs, targets):\n","                    iou = calculate_iou(pred, target)\n","                    total_val_iou += iou.item()\n","                    num_val_batches += 1\n","        \n","        val_loss = val_loss / len(val_dataloader.dataset)\n","        val_iou = total_val_iou / num_val_batches if num_val_batches > 0 else 0.0\n","        \n","        print(f\"Epoch {epoch}/{num_epochs}, train loss: {train_loss:.4f}, train IoU: {train_iou:.4f}, val loss: {val_loss:.4f}, val IoU: {val_iou:.4f}\\n\")\n","        history[\"loss\"].append(train_loss)\n","        history[\"val_loss\"].append(val_loss)\n","        history[\"iou\"].append(train_iou)\n","        history[\"val_iou\"].append(val_iou)\n","        \n","        # EARLY STOPPING\n","        if early_stopper is not None and early_stopper.should_stop(val_loss):\n","            print(\"Early stopping triggered.\")\n","            break\n","    \n","    # END OF TRAINING\n","    end_time_sec = time.time()\n","    total_time_sec = end_time_sec - start_time_sec\n","    time_per_epoch_sec = total_time_sec / num_epochs\n","    print(f\"Time total:     {total_time_sec:.2f} sec\")\n","    print(f\"Time per epoch: {time_per_epoch_sec:.2f} sec\\n\")\n","    \n","    # PLOT CURVES\n","    if plot_figs:\n","        _, axes = plt.subplots(1, 2, figsize=(12, 5))\n","        axes[0].plot(history[\"loss\"], label=\"Train Loss\", color=\"blue\", marker=\"o\")\n","        axes[0].plot(history[\"val_loss\"], label=\"Validation Loss\", color=\"orange\", marker=\"x\")\n","        axes[0].set_xlabel(\"Number of Epochs\", fontsize=12)\n","        axes[0].set_ylabel(\"Loss\", fontsize=12)\n","        axes[0].set_title(\"Training and Validation Loss Over Epochs\", fontsize=14)\n","        axes[0].legend(loc=\"best\", fontsize=12)\n","        axes[0].grid(True, linestyle=\"--\", alpha=0.7)\n","        \n","        axes[1].plot(history[\"iou\"], label=\"Train IoU\", color=\"blue\", marker=\"o\")\n","        axes[1].plot(history[\"val_iou\"], label=\"Validation IoU\", color=\"orange\", marker=\"x\")\n","        axes[1].set_xlabel(\"Number of Epochs\", fontsize=12)\n","        axes[1].set_ylabel(\"IoU\", fontsize=12)\n","        axes[1].set_title(\"Training and Validation IoU Over Epochs\", fontsize=14)\n","        axes[1].legend(loc=\"best\", fontsize=12)\n","        axes[1].grid(True, linestyle=\"--\", alpha=0.7)\n","        \n","        plt.tight_layout()\n","        plt.show()\n","    \n","    if save_filepath is not None:\n","        torch.save(model, save_filepath)\n","    \n","    return model, history\n","\n","num_epochs = 1\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.classifier[6].parameters(), lr=0.001)\n","early_stopper = EarlyStopper(patience=3, delta=0.001)\n","model, history = train_bbox_regression_model(\n","    model=model,\n","    optimizer=optimizer,\n","    criterion=criterion,\n","    train_dataloader=train_dataloader,\n","    val_dataloader=test_dataloader,\n","    num_epochs=num_epochs,\n","    device=device,\n","    scheduler=None,\n","    plot_figs=True,\n","    nb_batches_to_display=2,\n","    early_stopper=early_stopper,\n","    save_filepath=None\n",")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
